{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "37d13b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请输入关键字：bev\n",
      "输入最远时间（格式：YYYY-mm-dd）：2023-10-20\n",
      "输入最近时间（格式：YYYY-mm-dd）：2023-10-25\n",
      "是否需要摘要（yes/no）：no\n",
      "一次查找几篇论文：2\n",
      "标题：U-BEV: Height-aware Bird's-Eye-View Segmentation and Neural Map-based Relocalization\n",
      "pdf_url\n",
      "摘要：Efficient relocalization is essential for intelligent vehicles when GPS reception is insufficient or sensor-based localization fails. Recent advances in Bird's-Eye-View (BEV) segmentation allow for accurate estimation of local scene appearance and in turn, can benefit the relocalization of the vehicle. However, one downside of BEV methods is the heavy computation required to leverage the geometric constraints. This paper presents U-BEV, a U-Net inspired architecture that extends the current state-of-the-art by allowing the BEV to reason about the scene on multiple height layers before flattening the BEV features. We show that this extension boosts the performance of the U-BEV by up to 4.11 IoU. Additionally, we combine the encoded neural BEV with a differentiable template matcher to perform relocalization on neural SD-map data. The model is fully end-to-end trainable and outperforms transformer-based BEV methods of similar computational complexity by 1.7 to 2.8 mIoU and BEV-based relocalization by over 26% Recall Accuracy on the nuScenes dataset.\n",
      "        △ Less\n",
      "U-BEV: Height-aware Bird's-Eye-View Segmentation and Neural Map-based Relocalization.pdf 下载完成\n",
      "标题：ScalableMap: Scalable Map Learning for Online Long-Range Vectorized HD Map Construction\n",
      "pdf_url\n",
      "摘要：We propose a novel end-to-end pipeline for online long-range vectorized high-definition (HD) map construction using on-board camera sensors. The vectorized representation of HD maps, employing polylines and polygons to represent map elements, is widely used by downstream tasks. However, previous schemes designed with reference to dynamic object detection overlook the structural constraints within linear map elements, resulting in performance degradation in long-range scenarios. In this paper, we exploit the properties of map elements to improve the performance of map construction. We extract more accurate bird's eye view (BEV) features guided by their linear structure, and then propose a hierarchical sparse map representation to further leverage the scalability of vectorized map elements and design a progressive decoding mechanism and a supervision strategy based on this representation. Our approach, ScalableMap, demonstrates superior performance on the nuScenes dataset, especially in long-range scenarios, surpassing previous state-of-the-art model by 6.5 mAP while achieving 18.3 FPS. Code is available at https://github.com/jingy1yu/ScalableMap.\n",
      "        △ Less\n",
      "ScalableMap: Scalable Map Learning for Online Long-Range Vectorized HD Map Construction.pdf 下载完成\n",
      "共下载2篇论文。\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pdfkit\n",
    "import os\n",
    "\n",
    "def crawl_arxiv_papers():\n",
    "    try:\n",
    "        # 输入关键字和其他参数\n",
    "        keyword = input(\"请输入关键字：\")\n",
    "        from_year = input(\"输入最远时间（格式：YYYY-mm-dd）：\")\n",
    "        to_year = input(\"输入最近时间（格式：YYYY-mm-dd）：\")\n",
    "        abstract_required = input(\"是否需要摘要（yes/no）：\").lower()\n",
    "        num_papers_to_fetch = int(input(\"一次查找几篇论文：\"))\n",
    "        count = 0\n",
    "        # 构建查询URL\n",
    "        #query_url = f\"https://arxiv.org/search/?searchtype=all&query={keyword}&max_date={max_year}\"\n",
    "        query_url = f\"https://arxiv.org/search/advanced?advanced=&terms-0-operator=AND&terms-0-term={keyword}&terms-0-field=all&classification-physics_archives=all&classification-include_cross_list=include&date-year=&date-filter_by=date_range&date-from_date={from_year}&date-to_date={to_year}&date-date_type=submitted_date&abstracts=show&size=50&order=-announced_date_first\"\n",
    "        # 发送HTTP请求并获取页面内容\n",
    "        response = requests.get(query_url)\n",
    "        response.raise_for_status()  # 检查是否有HTTP错误\n",
    "\n",
    "        # 使用BeautifulSoup解析页面内容\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # 提取论文信息\n",
    "        paper_list = soup.find_all('li', class_='arxiv-result')\n",
    "\n",
    "        if len(paper_list) == 0:\n",
    "            print(\"未找到匹配的论文。\")\n",
    "        else:\n",
    "            # 创建下载文件夹\n",
    "            download_folder = \"G:\\\\3D目标检测\\\\test\"\n",
    "            os.makedirs(download_folder, exist_ok=True)\n",
    "\n",
    "            # 打印论文信息和下载\n",
    "            for i in range(len(paper_list)):\n",
    "                if  i < num_papers_to_fetch :\n",
    "                    paper = paper_list[i]\n",
    "                    title = paper.find('p', class_='title is-5 mathjax').text.strip()\n",
    "                    abstract = paper.find('span', class_='abstract-full has-text-grey-dark mathjax').text.strip()\n",
    "                    pdf_url = paper.find('a', text='pdf')['href']\n",
    "\n",
    "                    print(f\"标题：{title}\")\n",
    "                    if abstract_required :\n",
    "                        print('pdf_url')\n",
    "                        print(f\"摘要：{abstract}\")\n",
    "\n",
    "                    try:\n",
    "                    # 下载PDF文件到指定文件夹\n",
    "                        new_title = title.replace(\":\", \"\")\n",
    "                        pdf_filename = os.path.join(download_folder, f\"{new_title}.pdf\")\n",
    "                        pdf_response = requests.get(pdf_url)\n",
    "                        with open(pdf_filename, 'wb') as pdf_file:\n",
    "                            pdf_file.write(pdf_response.content)\n",
    "                        print(f\"{title}.pdf 下载完成\")\n",
    "                        count +=1\n",
    "\n",
    "                    except Exception as pdf_error:\n",
    "                        print(f\"下载 {title}.pdf 时出现错误：{pdf_error}\")\n",
    "\n",
    "        print(f\"共下载{count}篇论文。\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"出现错误：{e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    crawl_arxiv_papers()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f2a10645",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (3986219201.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_5824\\3986219201.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    query_url = f\"https://arxiv.org/search/advanced?advanced=&terms-0-operator=AND&terms-0-term={keyword}&\\n\u001b[0m\n\u001b[1;37m                                                                                                            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f726171",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://arxiv.org/search/advanced?advanced=&terms-0-operator=AND&terms-0-term={keyword}&terms-0-field=all&classification-physics_archives=all&classification-include_cross_list=include&date-year=&date-filter_by=date_range&date-from_date={from_year}&date-to_date={to_year}&date-date_type=submitted_date&abstracts=show&size=50&order=-announced_date_first"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
